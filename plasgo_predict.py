from datasets import load_dataset
from transformers import TrainingArguments, Trainer
from transformers import BertConfig
from collections import defaultdict
import argparse, os, sys
import numpy as np
import time
import torch
import pickle as pkl
from model import plasgo_model
start = time.time()


#############################################################
########################  Parameters  #######################
#############################################################
parser = argparse.ArgumentParser(description="""PlasGO is a Python library for predicting GO terms of plasmid-encoded proteins.
                                 PlasGO is designed as a hierarchical architecture that leverages the powerful foundation protein language model (ProtTrans-ProtT5) to learn the local context within protein sentences and a BERT model to capture the global context within plasmid sentences.""")
parser.add_argument('--midfolder', help='folder to store the intermediate files (generated by preprocessing.py), default: temp', type=str, default='temp')
parser.add_argument('--model_path', help='path of the folder storing the downloaded or your customized models, default: models', type=str, default='models')
parser.add_argument('--out', help='path to store the prediction results, default: results', type=str, default='results')
parser.add_argument('--min_prob', help='the minimum probability for determining a high-confidence GO term prediction (the maximum value is limited to 0.3), default: 0.3', type=float, default=0.3)
parser.add_argument('--device', help="device utilized for GO term prediction ('gpu' or 'cpu'), default: 'gpu'", type=str, default = 'gpu')
parser.add_argument('--batch_size', help="batch size (plasmid sentence count in a batch) for GO term prediction. If your GPU is out of memory during prediction, you can try to reduce this parameter, default: 32", type=int, default = 32)
inputs = parser.parse_args()


#############################################################
########################  Help info  ########################
#############################################################
def help_info():
    print('')
    print("""Usage of plasgo_predict.py:
        [--midfolder MIDFOLDER] folder to store the intermediate files (generated by preprocessing.py), default: temp
        [--model_path MODEL_PATH] path of the folder storing the downloaded or your customized models, default: models
        [--out OUT] path to store the prediction results, default: results
        [--min_prob MIN_PROB] the minimum probability for determining a high-confidence GO term prediction (the maximum value is limited to 0.3), default: 0.3
        [--device DEVICE] device utilized for GO term prediction ('gpu' or 'cpu'), default: 'gpu'
        [--batch_size BATCH_SIZE] batch size (plasmid sentence count in a batch) for GO term prediction. If your GPU is out of memory during prediction, you can try to reduce this parameter, default: 32
    """)


#############################################################
######################  Check folders  ######################
#############################################################
out_fn = inputs.midfolder
if not os.path.exists(out_fn):
    print(f"Error! The intermediate folder '{out_fn}' is unavailable. Please use the option '--midfolder' to indicate the directory where the intermediate files generated by 'preprocessing.py' are stored.")
    help_info()
    sys.exit()

mdl_fn = inputs.model_path
if not os.path.exists(mdl_fn):
    print(f"Error! The model folder '{mdl_fn}' is unavailable. Please use the option '--model_path' to indicate the folder of the downloaded or your customized models.")
    help_info()
    sys.exit()

res_fn = inputs.out
if not os.path.isdir(res_fn):
    os.makedirs(res_fn)


#############################################################
#####################  Hyperparameters  #####################
#############################################################
batch_size = inputs.batch_size
max_len = 56
hidden_size = 512
sigmoid = torch.nn.Sigmoid()

device_opt = inputs.device
if(device_opt=='cpu'):
    device = torch.device("cpu")
    print("Running GO term prediction with CPU ...")
else:
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    if(device==torch.device("cuda")):
        print("GPU detected. Running GO term prediction with GPU ...")        
    else:
        print("GPU not detected. Running GO term prediction with CPU ...")


#############################################################
#######################  Load dataset  ######################
#############################################################
test_csv_path = f'{out_fn}/plasmids.csv'
dataset = load_dataset('csv', data_files={'test': test_csv_path})
prot_idx = pkl.load(open(f'{out_fn}/prot_idx.dict', 'rb'))
protein_ids = dataset['test']['proteins']
sentence_num = len(protein_ids)
protein_ids = ';'.join(protein_ids)
protein_ids = protein_ids.split(';')
protein_num = len(set([i for i in protein_ids if i!='None']))
print(f'{protein_num} proteins in {sentence_num} plasmid sentences to be predicted ...')


def preprocess_data(examples):
    encoding = {}
    # protein indices
    proteins = examples["proteins"]
    protein_indices = []
    for sentence in proteins:
        prots = sentence.split(';')
        tmp_list = []
        for prot in prots:
            if(prot == 'None'):
                tmp_list.append(0)
            else:
                tmp_list.append(prot_idx[prot])
        protein_indices.append(tmp_list)
    encoding['proteins'] = protein_indices
    return encoding


encoded_dataset = dataset.map(preprocess_data, batched=True, num_proc=4, remove_columns=dataset['test'].column_names, keep_in_memory=True)
encoded_dataset.set_format("torch")


#############################################################
#########################  Predict!  ########################
#############################################################
# arguments for Trainer
test_args = TrainingArguments(
    output_dir = out_fn,
    do_train = False,
    do_predict = True,
    per_device_eval_batch_size = batch_size,
    dataloader_drop_last = False
)


def add_res(label, res_dict, protein, p):
    try:
        res_dict[protein][label].append(p)
    except:
        res_dict[protein][label] = [p]


labels_all = pkl.load(open(f'{mdl_fn}/labels.dict', 'rb'))
raw_embed = pkl.load(open(f'{out_fn}/raw_embeddings.pkl', 'rb'))
prob_cutoff = inputs.min_prob if inputs.min_prob<0.3 else 0.3
res_list = defaultdict(list)
for Class in ['mf', 'bp', 'cc']:
    dropout_rate = 0.1 if Class in ['bp', 'mf'] else 0.2
    layer_num = 4 if Class in ['bp', 'mf'] else 2
    labels = labels_all[Class]
    labels = {y:x for x,y in labels.items()}
    elusive_set = set([i for i in labels if labels[i][0]=='*'])
    label_num = len(labels)

    # load configuration for the global BERT module
    config = BertConfig(
        vocab_size=2,  # not in use
        hidden_size=hidden_size,
        num_hidden_layers=layer_num,
        num_attention_heads=8,
        max_position_embeddings=max_len,
        num_labels=label_num,
        intermediate_size = hidden_size*4,
        hidden_dropout_prob = dropout_rate,
        attention_probs_dropout_prob = dropout_rate)
    model = plasgo_model.from_pretrained(f'{mdl_fn}/{Class}', config=config, Class=Class, raw_embed=raw_embed)

    # init trainer
    trainer = Trainer(
        model = model,
        args = test_args)
    test_results = trainer.predict(encoded_dataset['test'])
    
    # Predicted results
    logits = test_results[0][0]
    logits = torch.Tensor(logits).to('cpu')
    logits = torch.reshape(logits, (-1, label_num))
    probs = sigmoid(logits)

    # Confidence scores
    scores = test_results[0][1]
    scores = torch.Tensor(scores).to('cpu')
    scores = torch.reshape(scores, (-1, label_num))

    # filter high-confidence GO term predictions
    res_dict = defaultdict(dict)
    idx = 0 # for protein
    for prob in probs:
        protein = protein_ids[idx]
        score = scores[idx]
        idx+=1
        if(protein=='None'):
            continue
        for iidx in range(label_num):   # for label
            if(iidx in elusive_set):
                continue
            p = prob[iidx].item()
            p = round(p, 2)
            if(p<prob_cutoff):
                continue
            if(p>=0.425 and p<=0.575):
                add_res(labels[iidx], res_dict, protein, p)
                continue
            elif(Class!='bp' and p>0.575):
                add_res(labels[iidx], res_dict, protein, p)
                continue
            if(score[iidx]<0.95):
                continue
            add_res(labels[iidx], res_dict, protein, p)
    
    # average the probabilities
    for protein in res_dict:
        for GO in res_dict[protein]:
            prob = np.mean(res_dict[protein][GO])
            prob = round(prob, 2)
            res = [GO, prob, Class]
            res_list[protein].append(res)


#############################################################
#######################  Write output  ######################
#############################################################
rep_go = pkl.load(open(f'{mdl_fn}/rep_go.dict', 'rb'))
rep_go = {x:','.join(y) for x,y in rep_go.items()}
f = open(f'{res_fn}/results.tsv', 'w')
f.write(f'Protein ID\tRepresentative GO term\tGO category\tProbability\tMember GO terms in the cluster\n')
for protein in res_list:
    for res in res_list[protein]:
        f.write(f'{protein}\t{res[0]}\t{res[2].upper()}\t{res[1]}\t{rep_go[res[0]]}\n')
print(f'The prediction results have been saved in {res_fn}/results.tsv.')


end = time.time()
print(f'The total time for GO term prediction is {end-start}s.')
